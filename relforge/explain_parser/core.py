"""Parse elasticsearch explains into tensorflow graphs

Lucene explains contain the full scoring equation that was used at runtime,
including similarity parameters and plenty of metrics that were looked up to
answer the query.  Tuning a scoring function by re-running the queries is
possible but very slow. With the values extracted from the explains and a
tensorflow graph of the equation built up simple scoring functions can be run
at speeds in excess of 1M hits/sec on a modest laptop.

The quick evaluation of millions of hits opens up new possibilities in tuning
the scoring queries.

IMPORTANT: This is very alpha stage, and likely only works for the query
parameters  and explains explicitly spelled out in the test suite. Some
elasticsearch queries, like `query_string`, will likely never be supported
here.

== Overview

1) Parse the source elasticsearch query into a parser specialized
   to that query
2) Parse explains for individual hits into explain objects. Feature
   vectors can be extracted from these.
3) Merge explains from many hits until all parsers created in step 1
   are satisfied they have seen the full scoring equation.
4) Convert the merged explain into a tensorflow graph

== elasticsearch query -> explain parser

The primary entry point here is RootExplainParser.from_query. This accepts the
root of an elasticserach query, including `query` and `rescore` keys, and
generates a parser.  Individual query parsers are registered with the
`register_parser` decorator. Generic elasticsearch queries  are parsed using
the registered parsers by calling `explain_parser_from_query`

== explain parser -> explain

This is a complete mess, and is buried in assumptions about what the explains looked like
when writing the code. The assertions scattered everywhere hopefully cover the assumptions
made and will catch changes in updated lucene versions that break these assumptions.

Each ExplainParser has a `parse` method that accepts a single explain detail. It must
either accept it and return an Explain object, or raise an IncorrectExplainException.
The IncorrectExplainException's are necessary because there is no direct link between
the explain and the original nodes in the graph. For example a bool query could have
4 should statements but only 1 matches. When run through the `parse_list` function
each parser will be tried against the explain until one accepts it.

For the most part the parsers check the description and maybe a little structure
to decide if they should throw an IncorrectExplainException. Once that decision
is made assertions are used to verify things look the way they are expected.

== feature vector extraction

Most of the feature vector handling is via `BaseExplain.feature_vec`.
This merges the feature vectors of child explains, applies naming prefixes, and
asserts no duplicate feature vectors are being returned. The most common
way to add a value to the feature vector is for the parser to generate a
PassThruExplain object, which will turn the `value` field of the explain
into a feature vector element.

Feature vectors are always returned as a list of 1 or more floats, never
a scalar. This is necessary to support explains with varied length feature
vectors, specifically match queries which can match many individual terms.
At feature extraction times the width of these vectors can vary, and they
are padded with 0's when running the graph.

== explain merging

Explain merging is the process of taking two explains generated by the same ExplainParser
and asking the parser to merge them. When generating explains the original parser
is attached as a property so we have access to the right parser to merge with.

Most child merging is handled with the `merge_children` function which will
look through two lists of children, separate into the unique set of parsers,
and merge parsers with multiple elements.

Explain merging is the reason we need ExplainParsers specialized to each query
type, the explains from multiple hits that trigger different parts of a query
are hard to reason about directly. We need the extra context of knowing
approximately what lucene queries were constructed under the hood and what they
should look like to merge explains reliably.

== convert to tensorflow graph

Converting to a tensorflow graph is straight forward once the above is all worked
out. For the most part explains will either take a product or sum of their children,
and specialized explains (tfNorm, dismax, etc) implement custom logic that
recreates the appropriate scoring equation.

"""
from collections import defaultdict
from functools import reduce

import tensorflow as tf

from relforge.explain_parser.utils import (
    isclose, join_name, name_fixer, clean_newlines)


# Full explain parser implementations
PARSERS = {}


def register_parser(name):
    def inner(fn):
        assert name not in PARSERS
        PARSERS[name] = fn
        return fn
    return inner


def explain_parser_from_query(query, name_prefix):
    """Create an explain parser from an elasticsearch query"""
    assert len(query) == 1
    query_type = next(iter(query.keys()))
    if query_type not in PARSERS:
        raise Exception('Unsupported query: {}'.format(query_type))
    options = query[query_type]
    return PARSERS[query_type](options, name_prefix)


@register_parser("template")
def parser_for_template_query(options, name_prefix):
    # Templates are invisible in the returned explain
    # TODO: apply template?
    return explain_parser_from_query(options['inline'], name_prefix)


class IncorrectExplainException(Exception):
    pass


def num_complete_children(children):
    return sum(1 for child in children if child.is_complete)


def parse_list(available_parsers, lucene_details, catch_errors=True):
    """Apply a list of explain parsers to a list of details"""
    remaining_parsers = list(available_parsers)
    parsed = []
    remaining_details = []
    for child in lucene_details:
        for i, parser in enumerate(remaining_parsers):
            try:
                parsed_child = parser.parse(child)
            except IncorrectExplainException:
                # We dont really know what parsers apply to what details, so
                # the standard case is to catch errors and try another parser.
                # This can be disabled for debugging to help figure out why
                # something wont parse.
                if not catch_errors:
                    raise
                continue
            remaining_parsers.pop(i)
            # None is returned for non-contributing explains
            if parsed_child is not None:
                parsed.append(parsed_child)
            break
        else:
            remaining_details.append(child)
    return remaining_parsers, remaining_details, parsed


def merge_children(a, b, all_parsers):
    # Match up children with our parsers
    parsers_by_hash = {hash(p): p for p in all_parsers}
    grouped = defaultdict(list)
    for name, children in (('a', a), ('b', b)):
        for child in children:
            if child.parser_hash not in parsers_by_hash:
                raise Exception('Unexpected parser not in all_parsers: {}'.format(child.parser))
            grouped[child.parser_hash].append((name, child))
    # Merge together anything we can
    all_children = []
    for parser_hash, children in grouped.items():
        if len(children) == 1:
            all_children.append(children[0][1])
        elif len(children) == 2:
            # sanity check these didn't come from the same side of the merge.
            child_names = {name for name, child in children}
            assert 2 == len(child_names)
            parser = parsers_by_hash[parser_hash]
            # TODO: explain why these indices
            all_children.append(parser.merge(children[0][1], children[1][1]))
        else:
            raise Exception('Expected 1 or 2 children per parser')
    return all_children


class BaseExplainParser(object):
    def __init__(self, name_prefix=None):
        self.name_prefix = name_prefix

    def parse(self, lucene_explain):
        """Parse a lucene explain node.

        Recieves a lucene explanation node and either returns
        a BaseExplain or raises an IncorrectExplainException
        when the explain is not parsable.
        """
        raise NotImplementedError(type(self))

    def merge(self, a, b):
        """Merge two explains returned by self.parse.

        ????
        """
        raise NotImplementedError(type(self))


class RootExplainParser(BaseExplainParser):
    """Represents the entirety of an elasticsearch query.

    RootExplainParser is the entry point of the explain parsing system.  The
    from_query method accepts the same json as the elasticsearch _search
    endpoint and the parse method accepts the _explanation field of a hit
    generated by running _search with that query.
    """
    def __init__(self, root, name_prefix=''):
        super(RootExplainParser, self).__init__(name_prefix)
        self.root = root

    @classmethod
    def from_query(cls, root, name_prefix=''):

        query = explain_parser_from_query(root['query'], name_prefix=join_name(name_prefix, 'query'))
        query = TypeExplainParser(query)
        if 'rescore' in root:
            query = RescoreExplainParser.from_query(root['rescore'], query, name_prefix)
        return cls(query, name_prefix)

    def parse(self, lucene_explain):
        lucene_explain = clean_newlines(lucene_explain)
        return RootExplain(lucene_explain=lucene_explain,
                           inner_explain=self.root.parse(lucene_explain),
                           parser_hash=hash(self),
                           name_prefix=self.name_prefix)

    def merge(self, a, b):
        """Merge two explains returned by self.parse"""
        return self.root.merge(a, b)


class TypeExplainParser(BaseExplainParser):
    def __init__(self, inner):
        super(TypeExplainParser, self).__init__(inner.name_prefix)
        assert isinstance(inner, BaseExplainParser)
        self.inner = inner

    def parse(self, lucene_explain):
        if len(lucene_explain['details']) > 1:
            maybe_type_filter = lucene_explain['details'][1]
            if self.check_type_filter(maybe_type_filter):
                assert lucene_explain['description'] == 'sum of:'
                assert len(lucene_explain['details']) == 2
                lucene_explain = lucene_explain['details'][0]

        return self.inner.parse(lucene_explain)

    def check_type_filter(self, lucene_explain):
        return (
            lucene_explain['description'] == 'match on required clause, product of:'
            and lucene_explain['value'] == 0
            and len(lucene_explain['details']) == 2
            and lucene_explain['details'][0]['description'] == '# clause'
            and lucene_explain['details'][1]['description'] in ('#*:* -_type:__*, product of:', '_type:page, product of:'))  # noqa: E501

    def merge(self, a, b):
        return self.inner.merge(a, b)


class RescoreExplainParser(BaseExplainParser):
    def __init__(self, rescore_queries, main_query_parser, name_prefix):
        super(RescoreExplainParser, self).__init__(name_prefix=name_prefix)
        self.rescore_queries = rescore_queries
        self.main_query_parser = main_query_parser

    @classmethod
    def from_query(cls, root, main_query_parser, name_prefix):
        assert isinstance(root, list)
        prefix = join_name(name_prefix, 'rescore')
        rescore_queries = [RescoreQueryExplainParser.from_query(rescore, prefix, i) for i, rescore in enumerate(root)]
        return RescoreExplainParser(rescore_queries, main_query_parser, name_prefix=prefix)

    @staticmethod
    def extract_query(root_lexplain):
        current = root_lexplain
        for rescore in RescoreExplainParser.rescore_iterator(root_lexplain):
            current = rescore['details'][0]['details'][0]
        return current

    @staticmethod
    def rescore_iterator(root_lexplain):
        """Yields the lucene explanation of every rescore nodes
        Args:
            root_lexplain (root_lexplain): current lucene explain node

        Yields:
            dict:
        """
        current = root_lexplain
        while True:
            if len(current['details']) != 2:
                break
            for child in current['details']:
                if child['description'] != 'product of:' or \
                        len(child['details']) != 2:
                    return

            prim = current['details'][0]
            sec = current['details'][1]
            if prim['details'][1]['description'] != 'primaryWeight':
                break
            assert sec['details'][1]['description'] == 'secondaryWeight'
            yield current
            current = prim['details'][0]

    def parse(self, lucene_explain):
        """Parse rescore elements in the explanation
        Args:
            lucene_explain (dict): lucene explanation
        Returns:
            BaseExplain
        """
        previous_explain = self.main_query_parser.parse(RescoreExplainParser.extract_query(lucene_explain))
        # reverse the list from the deepest to the shallowest (first to last as declared in the es query)
        rescores_iterator = reversed(list(RescoreExplainParser.rescore_iterator(lucene_explain)))
        rescore_lexplain = next(rescores_iterator, None)
        for rescore_parser in iter(self.rescore_queries):
            # some rescore query may not appear in the explain
            # (if they translate to the match_none query during rewrite)
            # e.g. token_count_router
            if rescore_parser.acceptable(rescore_lexplain):
                previous_explain = rescore_parser.parse_rescore(rescore_lexplain, previous_explain)
                rescore_lexplain = next(rescores_iterator, None)
            else:
                previous_explain = RescoreExplain.missing(rescore_lexplain['value'], previous_explain, self.name_prefix)
            previous_explain.parser_hash = hash(self)

        return previous_explain

    def merge(self, a, b):
        if a.is_complete:
            return a
        if b.is_complete:
            return b
        nextA = a
        nextB = b
        for unused in reversed(self.rescore_queries):
            assert isinstance(nextA, RescoreExplain)
            assert isinstance(nextB, RescoreExplain)
            assert nextA.parser_hash == nextB.parser_hash
            if nextA.rescore_explain is None and nextB.rescore_explain is not None:
                nextA.operation_explain = nextB.operation_explain
                nextA.name = nextB.name
                nextA.description = nextB.description
                saveInnerA = nextA.inner_query_explain
                nextA.children = nextB.children
                nextA.inner_query_explain = nextB.inner_query_explain
                nextA = nextA.inner_query_explain
                nextB = saveInnerA
            else:
                nextA = nextA.inner_query_explain
                nextB = nextB.inner_query_explain
        return a


class RescoreQueryExplainParser:
    def __init__(self, score_mode, rescore_query, query_weight, rescore_query_weight, name_prefix):
        """
        A rescore query
        Arguments
        rescore_query_weight (float)
        query_weight (float)
        score_mode (str)
        rescore_query (BaseExplainParser)
        """
        self.rescore_query_weight = rescore_query_weight
        self.query_weight = query_weight
        self.score_mode = score_mode
        self.rescore_query = rescore_query
        self.name_prefix = name_prefix

    @classmethod
    def from_query(cls, rescore, name_prefix, index):
        assert 'query' in rescore, "only rescores of type 'query' are supported"
        rescore = rescore.get('query')
        score_mode = rescore.get('score_mode', 'total')
        rescore_weight = rescore.get('rescore_query_weight', 1.0)
        query_weight = rescore.get('query_weight', 1.0)
        prefix = join_name(name_prefix, str(index))
        query = explain_parser_from_query(rescore.get('rescore_query'), prefix)
        return cls(score_mode=score_mode,
                   rescore_query=query,
                   query_weight=query_weight,
                   rescore_query_weight=rescore_weight,
                   name_prefix=prefix)

    def parse_rescore(self, lucene_explain, inner_explain):
        assert self.acceptable(lucene_explain)
        if self.score_mode == 'total':
            op_type = SumExplain
        else:
            assert self.score_mode == 'multiply'
            op_type = ProductExplain
        assert len(lucene_explain['details']) == 2

        query_exp = self._parse_rescore_weights(lucene_explain['details'][0],
                                                lambda inner_lexplain: inner_explain,
                                                'primaryWeight',
                                                self.query_weight)
        rescore_query_exp = self._parse_rescore_weights(lucene_explain['details'][1],
                                                        lambda inner_lexplain: self.rescore_query.parse(inner_lexplain),
                                                        'secondaryWeight',
                                                        self.rescore_query_weight)
        operation_explain = op_type(lucene_explain,
                                    name_prefix=self.name_prefix,
                                    children=[query_exp, rescore_query_exp],
                                    expected_children=2)
        return RescoreExplain(lucene_explain=lucene_explain,
                              name_prefix=self.name_prefix,
                              operation_explain=operation_explain,
                              inner_query_explain=query_exp,
                              rescore_explain=rescore_query_exp)

    def _parse_rescore_weights(self, lucene_explain, next_parser, expectedWeightType, expectedWeight):
        assert lucene_explain['description'] == 'product of:'
        assert len(lucene_explain['details']) == 2
        q_lexp, w_lexp = lucene_explain['details']
        assert w_lexp['description'] == expectedWeightType
        assert isclose(w_lexp['value'], expectedWeight)
        q = next_parser(q_lexp)
        name = 'query_weight' if expectedWeightType == 'primaryWeight' else 'rescore_query_weight'
        w = TunableVariableExplain(w_lexp,
                                   name=name,
                                   name_prefix=self.name_prefix)
        return ProductExplain(lucene_explain, self.name_prefix, children=[q, w], expected_children=2)

    def acceptable(self, lucene_explain):
        if self.score_mode == 'total' and \
                lucene_explain['description'] != 'sum of:':
            return False
        elif self.score_mode == 'multiply' and \
                lucene_explain['description'] != 'product of:':
            return False

        if len(lucene_explain['details']) != 2:
            return False
        for child in lucene_explain['details']:
            if child['description'] != 'product of:' or \
                    len(child['details']) != 2:
                return False

        q_exp, q_weight = lucene_explain['details'][0]['details']
        r_exp, r_weight = lucene_explain['details'][1]['details']

        if q_weight['description'] != 'primaryWeight':
            return False
        if not isclose(q_weight['value'], self.query_weight):
            return False

        if r_weight['description'] != 'secondaryWeight':
            return False
        if not isclose(r_weight['value'], self.rescore_query_weight):
            return False

        return True


class BaseExplain(object):
    """BaseExplain and it's subclasses represent the parsed explain hierarchy.

    TODO: WRITE MORE!!!
    """
    def __init__(self, lucene_explain, name_prefix, children=[], expected_children=None, name=None):
        self.description = lucene_explain['description']
        self.value = float(lucene_explain['value'])
        self.children = children
        self.name_prefix = name_prefix
        if expected_children is not None:
            self.expected_children = expected_children
        elif len(children) == 0:
            self.expected_children = 0
        else:
            raise Exception('expected_children must be provided')
        if name is None:
            self.name = None
        else:
            self.name = name_fixer(name)

    @property
    def children(self):
        return self._children

    @property
    def is_complete(self):
        assert self.expected_children is not None
        return self.expected_children == num_complete_children(self.children)

    @children.setter
    def children(self, value):
        assert value is not None, type(self).__name__
        assert all(isinstance(c, BaseExplain) for c in value), [type(c).__name__ for c in value]
        assert not any(c == self for c in value), "no recursion!"
        self._children = value

    @staticmethod
    def _concat_w_scalars(tensors):
        by_shape = {tuple(t.shape.as_list()): t for t in tensors}
        if len(by_shape) == 2 and () in by_shape:
            # reshape scalar to match type
            by_shape.pop(())
            shape = next(iter(by_shape.values())).shape
            tensors = [t if t.shape == shape else tf.reshape(t, shape) for t in tensors]
        return tf.concat(tensors, axis=1)

    def child_tensor(self, vecs):
        """Join children into a single tensor

        Parameters
        ----------
        vecs : dict
            dict from name to tensor for that feature vector

        Returns
        -------
        tf.Tensor
        """
        child_tensors = [child.to_tf(vecs) for child in self.children if child]
        child_tensors = [child for child in child_tensors if child is not None]
        if child_tensors:
            return self._concat_w_scalars(child_tensors)
        else:
            return tf.constant(0.0, name=self.name_prefix)

    def to_tf(self, vecs):
        """Transform explain into a tensorflow operation

        Parameters
        ----------
        vecs : dict
            dict from name to tensor for that feature vector

        Returns
        -------
        tf.Tensor
        """
        raise NotImplementedError(type(self))

    def feature_vec(self):
        """Extract feature vector from explain

        Returns
        -------
        dict
            dict from name to list of floats for that feature vector
        """
        data = {}
        for child in self.children:
            for k, v in child.feature_vec().items():
                if k in data:
                    raise Exception('Variable name conflict: {}'.format(k))
                data[k] = v
        return data

    def to_str_arr(self, indent):
        """Recursively convert self into an array of string representations"""
        output = [indent + str(self)]
        if self.children:
            assert all(isinstance(c, BaseExplain) for c in self.children)
            child_indent = indent + '  '
            for child in self.children:
                output.extend(child.to_str_arr(child_indent))
        return output

    def to_str(self, indent=''):
        return '\n'.join(self.to_str_arr(''))

    def __repr__(self):
        return self.to_str()

    def __str__(self):
        return '{}: {:.2f}, {}'.format(type(self).__name__, self.value, self.description)


class TunableVariableExplain(BaseExplain):
    """Treat the explain as a tunable value"""
    is_complete = True

    def __init__(self, *args, **kwargs):
        super(TunableVariableExplain, self).__init__(*args, **kwargs)
        if self.name is None:
            self.name = 'boost'

    def to_tf(self, vecs):
        return tf.get_variable(join_name(self.name_prefix, self.name), initializer=self.value)

    def feature_vec(self):
        return {}


class PassThruExplain(BaseExplain):
    """Insert the value of an explain into the feature vector"""
    is_complete = True

    def __init__(self, *args, **kwargs):
        super(PassThruExplain, self).__init__(*args, **kwargs)
        if self.name is None:
            self.name = self.description

    def to_tf(self, vecs):
        return vecs[join_name(self.name_prefix, self.name)]

    def feature_vec(self):
        return {join_name(self.name_prefix, self.name): [self.value]}


class GlobalConstantExplain(BaseExplain):
    """Treat the explain as a global constant, such as avgFieldLength"""
    is_complete = True

    def feature_vec(self):
        return {}

    def to_tf(self, vecs):
        # TODO: Does name need prefix attached?
        if self.name:
            name = self.name
        else:
            name = self.description.replace(' ', '-')
        return tf.constant(self.value, name=name)


class SumExplain(BaseExplain):
    boost = False  # TODO: What is this?

    def to_tf(self, vecs):
        # If we have no children this will return a constant scalar
        child_tensor = self.child_tensor(vecs)
        if child_tensor.shape == ():
            tensor = child_tensor
        else:
            tensor = tf.reduce_sum(child_tensor, 1)
            tensor = tf.reshape(tensor, shape=[-1, 1])
        return tensor


class ProductExplain(BaseExplain):
    def to_tf(self, vecs):
        if len(self.children) == 1:
            return self.children[0].to_tf(vecs)

        child_tensors = [child.to_tf(vecs) for child in self.children]
        child_tensors = [child for child in child_tensors if child is not None]
        n_dims = set(len(t.shape) for t in child_tensors)
        n_dims.discard(0)  # A scalar multiplies just fine
        if len(n_dims) != 1:
            for c, t in zip(self.children, child_tensors):
                print(str(c), str(t))
            raise Exception('All child tensors must have same number of dimensions')
        n_dims = n_dims.pop()
        if n_dims > 1:
            # TODO: Why was it tf.reduce_prod doesn't work here?
            tensor = reduce(lambda a, x: tf.multiply(a, x), child_tensors)
        elif any(len(t.shape) > 0 and t.shape[-1] != 1 for t in child_tensors):
            raise Exception('I dont like that tensor shape (why?)')
        else:
            # All children are scalar or single dimensional with a final width of 1
            child_tensor = tf.concat(child_tensors, axis=1)
            tensor = tf.reduce_prod(child_tensor, axis=1)
            tensor = tf.reshape(tensor, [-1, 1])
        return tensor


class RescoreExplain(BaseExplain):
    def __init__(self, lucene_explain, name_prefix, operation_explain=None,
                 inner_query_explain=None, rescore_explain=None):
        super(RescoreExplain, self).__init__(lucene_explain,
                                             children=[] if operation_explain is None else [operation_explain],
                                             expected_children=1,
                                             name_prefix=name_prefix)
        self.operation_explain = operation_explain
        self.inner_query_explain = inner_query_explain
        self.rescore_explain = rescore_explain

    def is_complete(self):
        return self.operation_explain is not None and self.operation_explain.is_complete()

    def to_tf(self, vecs):
        if self.operation_explain is None:
            raise IncorrectExplainException("Cannot build the equation: not all rescore queries have been seen")
        return self.operation_explain.to_tf(vecs)

    @classmethod
    def missing(cls, value, inner_query, name_prefix):
        return cls({'value': value, 'description': 'MISSING'}, inner_query_explain=inner_query, name_prefix=name_prefix)

    @classmethod
    def available(cls, lucene_explain, operation_explain, query_explain, rescore_explain, name_prefix):
        return cls(lucene_explain,
                   operation_explain=operation_explain,
                   inner_query_explain=query_explain,
                   rescore_explain=rescore_explain,
                   name_prefix=name_prefix)


class RootExplain(BaseExplain):
    def __init__(self, lucene_explain, inner_explain, parser_hash, name_prefix):
        super(RootExplain, self).__init__(lucene_explain,
                                          name_prefix=name_prefix,
                                          children=[inner_explain],
                                          expected_children=1,
                                          name=None)
        self.parser_hash = parser_hash

    def to_tf(self, vecs):
        return self.children[0].to_tf(vecs)
